# Markov Decision Process


## Motivation
In *K-arm bandit* problems, there is no reference of state which can represent different operating conditions (or different *real-world* situations) under which the algorithm is expected to perform, as human beings we regularly come across instances in which the same algorithm or mechanism operating in the same consistent manner yields different results when operating under different conditions. 

* For example - a car going around a corner at the same speed can spin out of control if there is rain or oil on the track but can stay under control if its a clear day and the track is good.


# Value Functions and Bellman Equation

